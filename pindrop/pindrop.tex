
\documentclass{article}

\usepackage{fullpage}
\usepackage{amsmath}

\title{Review of `PinDr0p: Using Single-Ended Audio Features to Determine Call Provenance`}
\author{Michael Deakin}

\begin{document}
\maketitle
This paper discusses a signal based method of call provenance.
It makes no assumptions about the accuracy of the information on the source of the phone call,
and instead uses the actual audio signal to identify the types of phone networks the signal traversed.
To do this, distinguishing features between signals which have travelled over specific types of networks are identified.
These are statistical features, so the resulting data on them is then classified by a machine learning algorithm.
The types of networks identified include VoIP with speech encoded with G.711, Speex, or iLBC,
cellular networks encoded with GSM-FR,
and dedicated PSTN networks encoded with G.711.
\section{VoIP Features}
One of the major distinguishing features of VoIP is that packets are frequently lost.
Thus, to detect a VoIP network, it makes sense to look for parts of the signal which are zeroed out,
where other information suggests it shouldn't be.
To do this, the Short Time Average Energy function is used, with a Hamming window function.
\begin{figure}[h]
  \[ E_n=\sum_{m=-\infty}^{\infty}y^2(m) w(n-m) \]
  \caption{Short Time Average Energy}
\end{figure}
\begin{figure}[h]
  \[ w(n)=\alpha - \beta \cos\Big(\frac{2\pi n}{N - 1}\Big) \]
  \caption{Hamming Window Function}
\end{figure}
Since packets contain at least 10 ms of audio represented by 80 samples of speech,
choosing a window length less than 80 samples causes multiple values of $E_n$ can be affected by a dropped packet.
This allows us to detect dropped packets by looking for a falling edge, a floor, and a rising edge.
If any of these characteristics are missing, it's not clear if a packet loss has occured,
and these packet drops cannot be detected with this method.
A test of this method on $15 s$ of audio showed a high correspondence between detected dropped packets and actual dropped packets.\\
Packet drops also tell us the codec used in the VoIP network.
The distinguishing feature is the length of the floor resulting from the dropped packet.
iLBC encodes $30 ms$ per packet, and Speex encodes $20 ms$ per packet.
G.729 encodes $10 ms$ per packet by default, and G.711 encodes $20 ms$ per packet by default;
so it is usually safe to assume these floor lengths correspond to these codec types.
Furthermore, since the case of multiple consecutive packets being dropped is rarer than a single packet being dropped,
the most frequent floor length will have a high correspondence with the codec type.\\
Some VoIP networks use a reactive recovery measure to detect lost packets and try to give a credible output signal.
This is done in one of several ways: Outputting silence, outputting noise,
and performing an interpolation based on previous packets.
The STE method described previously is capable of detecting the first two, with only an adjustment of the signal floor.
Unfortunately, the third method is the most common one, making detection more difficult;
but not impossible since these methods are generally deterministic.
This makes a detection a simple matter of looking at correlations between previous packets and the current one.\\
G.711 performs waveform substitution, repeating part of the previous packet, and is easy to detect.\\
iLBC uses a linear predictive coding method based on the source filter model of speech production.
This method inverse-filters the voiced sounds, leaving behind the original sound energy residual.
iLBC uses the residual, synthesis filters, and a dynamic codebook to compress the audio signal.
When a packet is lost, the decoder uses the residual from the previous signal,
and adds a random excitation to it.
It creates a new pitch synchronous residual {\bf(What is that?)} for the packet to be concealed.\\
To detect PLC in iLBC
{\bf(How do we know it's iLBC at this point? Is this indiscriminantly applied?
  Or is it guessed based on the improbability of other codecs being used?)},
the audio is split into $30 ms$ packets, as that is the default for iLBC.
The pitch synchronous residual is created from each packet and compared to the previous one.
The pitch synchronous residual is not usually highly correlated,
so a high correlation between these packets implies that the current one was lost
{\bf(How much does misalignment of the lost packet and the assumed packet affect this correlation?
  In the worst case, the guessed packets are exactly out of phase with the real packets.
  What is the expected correlation then,
  and how does it compare to the normal amount of correlation between two consecutive packets?
  Or is there a mechanism to detect when this happens and realign the guessed packets?
  Also, what happens in the case of two consecutive lost packets?
  Does it not try to conceal the second lost packet, or does it reuse the last received one?
  Does this occur frequently enough for it to be useful?)}.
In a test, this method only detected about $20\%$ of the concealed packets
{\bf(This does not bode well for my alignment concerns.
  But are they a problem that doesn't have another solution?
  If the entire audio is collected, or atleast from the start,
  will the alignment always be correct?)}.\\
{\bf Figure 8 shows the number of concealed packets detected at various packet loss rates.
  At $0\%$, the number of detected PLCs is very similar to $1\%$,
  but the number of detected PLCs at $5\%$ is entirely within the rates for the previous loss rates.
  Is an adaptive threshold being used to detect PLCs?
  If not, why is the number detected at $5\%$ entirely contained within the others?
  Only 40 $15 s$ samples were used in this test, so it could just be errors.
  Some quick math shows that ~25 packets should be lost in the $5\%$ case,
  and only ~5 in the $1\%$ case.
  At a $20\%$ detection rate from the original test,
  ~5 PLCs should be detected in the $5\%$ case, and ~1 in the $~1\%$ case.
  For $10\%$, ~50 packets should be lost, and ~10 PLCs should be detected.
  Only ~5 PLCs are detected though, suggesting much more testing is needed before conclusions can be drawn.
  Finally, the fact that any PLCs were detected at a loss rate of $0\%$
  is proof of a moderately large number of false positives.
  Thus, I don't any claim can be made yet of the actual loss rate based on this algorithm,
  especially at low loss rates.
  I'm also concerned about the ability to classify iLBC encoded data as VoIP as a result of this.}
\section{Noise Profiling}
PSTN and cellular networks have a very different problem which allows them to be identified.
The G.711 codec is typically used in PSTN networks, and does not use any compression.
This means noise is only introduced in the network (in low amounts),
and when the speech is being captured, due to imperfect microphones (most of the noise).
As a result, the noise is highly correlated to the signal.
This is multiplicative noise,
and its presence can be determined by the spectral level range and spectral level deviation.
The spectral clarity for this codec is also very high.
Spectral clarity quantifies the perceptible call quality of a network and codec
{\bf(What is spectral clarity?
  Is it a measure of how quickly the spectrum falls off?
  It's clearly classifiable by a machine, so there must be a mathematical relationship.)}.\\
Cellular networks, on the other hand, are bandwidth limited,
and use the compression codec GSM-FR.
This codec significantly reduces the spectral clarity of the signal.
\section{Classification}
A multi-label classifier using C4.5 decision trees is trained using speech samples.
C4.5 decision trees outperformed other classifiers such as Naive Bayes and Neural Networks in this task.
The features used are the packet loss detection output (codec + packet loss rate),
the PLC detection output (codec + packet concealment count),
the noise spectral metrics, and the P.563 scoring output (MOS score).
The P.563 is a single ended quality tool to obtain call quality metrics.
This helps determine how many different networks the call traversed,
as the call quality degrades with each transition
{\bf(Is this always true? Does a call degrade further after going through every type of network?)}.\\
This classification determines which networks the signal has traversed.
The classification does not determine the order of the networks that the signal traversed.
However, it does prevent adversaries from using VoIP to anonymously call large numbers of people pretending to be a local bank.
\section{Evaluation}
The evaluation is based on the accuracy of the classifier and the ability to consistently identify a call source.
This is performed by training the classifier with a set of speech samples subjected to representative traversal signals and degradations.
This includes converting between codecs with PJSIP, introducing noise, and losing packets where applicable.
Calls are assumed to traverse at most 3 networks.
\section{Classification Results}
A reduction technique is needed to convert a multi-label classification into a single label.
The reduction techniques compared are Binary Relevance (BR), Label Power set (LP), and Random k-Labelsets (RAkEL).
10-fold cross validation was then used to measure the accuracy under these techniques
{\bf(What is 10-fold cross validation?
  Divide the training set into 10 groups, then train 10 classifiers, each excluding one group.
  The resulting classifiers are then compared)}
The Hamming loss, accuracy, precision, and recall
of the classifiers with different reduction techniques was then compared.
RAkEL ended up with the best scores overall.
\section{Testing}
Various users each made 10 calls to the testbed in Atlanta from 16 different locations in the world.
The calls each lasted about $20 s$, from which features and profiles were extracted.
This was chosen as it was more than the $15 s$ required for the P.563 scoring.
$N$ of the 10 call sets were used to train a nueral network classifier,
where $N$ was varied between 1 and 5.
Even with only 1 of the 16 calls labeled,
the remaining 5 sets of calls are identified with the correct source label correctly $90\%$ of the time.
{\bf(The confusion matrix shows the call source label to be the location the call was made from.
  I would not expect this result to hold when more locations are added.
  How many calls total were in a single set? This is not given, but should be.)}.
Interestingly, local Vonage calls were more distinguishable by the high spectral level range than by the packet loss profile.
\section{Limitations}
Packet loss characteristics were heavily relied upon to differentiate VoIP fingerprints.
This means the system is vulnerable to temporary network issues.\\
Each source was associated with a single finger-print, explaining how they were able to identify the source so well.\\
Newer codecs have been introduced and are gaining traction,
and should be considered in future work.
\end{document}
